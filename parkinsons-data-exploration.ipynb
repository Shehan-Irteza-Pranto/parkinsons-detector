{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinson's Data Exploration\n",
    "\n",
    "This document will hold code that will allow us to gain insights on the parkinsons datasets that we have to work including disease classification, multiple sound recording, and telemonitoring. \n",
    "\n",
    "## Some Housekeeping\n",
    "We'll start by importing any necessary packages and pulling in the data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "dc = pandas.read_csv('./data/disease-classification/pd_speech_features.csv')\n",
    "msr_train = pandas.read_csv('./data/multiple-sound-recording/train_data.csv')\n",
    "msr_test = pandas.read_csv('./data/multiple-sound-recording/test_data.csv')\n",
    "te = pandas.read_csv('./data/telemonitoring/parkinsons_updrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Dataset Information\n",
    "\n",
    "### [Disease Classification (DC) Dataset](https://archive.ics.uci.edu/ml/datasets/Parkinson%27s+Disease+Classification#)\n",
    "The data used in this study were gathered from 188 patients with Parkinsons and 64 healthy individuals. Researchers recorded the participants sustaining the phonation of the vowel /a/ for three repetitions.\n",
    "\n",
    "Speech signal processing algorithms including Time Frequency Features, Mel Frequency Cepstral Coefficients (MFCCs), Wavelet Transform based Features, Vocal Fold Features and TWQT features were also applied to the speech recordings to extract clinically useful information for PD assessment.\n",
    "\n",
    "### [Multiple Sound Recording (MSR) Dataset](https://archive.ics.uci.edu/ml/datasets/Parkinson+Speech+Dataset+with++Multiple+Types+of+Sound+Recordings)\n",
    "The training data were gathered from 20 patients with Parkinsons and 20 health individuals. Multiple types of sound recordings were taken from each participant (listed below) and expert physicians assigned each participant a Unified Parkinsonâ€™s Disease Rating Scale (UPDRS) score. \n",
    "\n",
    "Utterances\n",
    "- 1: sustained vowel (aaaâ€¦â€¦)\n",
    "- 2: sustained vowel (oooâ€¦...)\n",
    "- 3: sustained vowel (uuuâ€¦...)\n",
    "- 4-13: numbers from 1 to 10\n",
    "- 14-17: short sentences\n",
    "- 18-26: words\n",
    "\n",
    "Features\n",
    "Training Data File:\n",
    "- column 1: Subject id\n",
    "\n",
    "- columns 2-27: features\n",
    "- features 1-5: Jitter (local),Jitter (local, absolute),Jitter (rap),Jitter (ppq5),Jitter (ddp),\n",
    "- features 6-11: Shimmer (local),Shimmer (local, dB),Shimmer (apq3),Shimmer (apq5), Shimmer (apq11),Shimmer (dda),\n",
    "- features 12-14: AC,NTH,HTN,\n",
    "- features 15-19: Median pitch,Mean pitch,Standard deviation,Minimum pitch,Maximum pitch,\n",
    "- features 20-23: Number of pulses,Number of periods,Mean period,Standard deviation of period, features 24-26: Fraction of locally unvoiced frames,Number of voice breaks,Degree of voice breaks\n",
    "\n",
    "- column 28: UPDRS\n",
    "- column 29: class information\n",
    "\n",
    "The testing data were gathered from 28 different patients with Parkinsons. The patients are asked to say only the sustained vowels 'a' and 'o' three times each, producing 168 recordings. The same 26 features are extracted from the voice samples.\n",
    "\n",
    "Utterances\n",
    "- 1-3: sustained vowel (aaaâ€¦â€¦)\n",
    "- 4-6: sustained vowel (oooâ€¦â€¦)\n",
    "\n",
    "### [Telemonitoring (TE) Dataset ](http://archive.ics.uci.edu/ml/datasets/Parkinsons+Telemonitoring)\n",
    "The data was gathered from 42 people with early-stage Parkinson's disease. There are 16 voice measures, and two regression measurements: motor UPDRS and total UPDRS. Each row of the dataset contain corresponds to one voice recording. There are around 200 recordings per patient, the subject number of the patient is identified in the first column.\n",
    "\n",
    "Features\n",
    "- subject# - Integer that uniquely identifies each subject\n",
    "- age - Subject age\n",
    "- sex - Subject gender '0' - male, '1' - female\n",
    "- test_time - Time since recruitment into the trial. The integer part is the number of days since recruitment.\n",
    "- motor_UPDRS - Clinician's motor UPDRS score, linearly interpolated\n",
    "- total_UPDRS - Clinician's total UPDRS score, linearly interpolated\n",
    "- Jitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP - Several measures of variation in fundamental frequency\n",
    "- Shimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA - Several measures of variation in amplitude\n",
    "- NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "- RPDE - A nonlinear dynamical complexity measure\n",
    "- DFA - Signal fractal scaling exponent\n",
    "- PPE - A nonlinear measure of fundamental frequency variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Similarities and Differences\n",
    "\n",
    "In this section we'll take a look at some of the similarities and differences across these 3 datasets. We can begin by looking at the shape of these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease Classification Dataset shape: (757, 755)\n",
      "Multiple Sound Recoring Training Dataset shape: (1039, 29)\n",
      "Multiple Sound Recoring Testing Dataset shape: (167, 28)\n",
      "Telemonitoring Datasetshape: (5875, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Disease Classification Dataset shape: {}\".format(dc.shape))\n",
    "print(\"Multiple Sound Recoring Training Dataset shape: {}\".format(msr_train.shape))\n",
    "print(\"Multiple Sound Recoring Testing Dataset shape: {}\".format(msr_test.shape))\n",
    "print(\"Telemonitoring Datasetshape: {}\".format(te.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately, we notice that the dimensionality of the DC dataset is very high in comparison to the other two datasets, with about 30 times the number of features. This is due to the speech signal processing algorithms that are run on the voice recordings on this dataset, including Time Frequency Features, Mel Frequency Cepstral Coefficients (MFCCs), Wavelet Transform based Features, Vocal Fold Features and TWQT features. These processes create many features.\n",
    "\n",
    "We also note that the DC and MSR datasets have a similar number of instances, while the TE dataset has over 5 times as many instances. None of these datasets are particularly large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization and Correlation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
